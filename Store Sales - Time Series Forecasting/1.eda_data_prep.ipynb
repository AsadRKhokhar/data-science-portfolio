{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the store sales dataset from Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading store-sales-time-series-forecasting.zip to /Users/bilalkhokhar/Desktop/asadrkhokar/data-science-portfolio\n",
      "  0%|                                               | 0.00/21.4M [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 21.4M/21.4M [00:00<00:00, 1.58GB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set a custom path with your desired folder\n",
    "custom_path = '/Users/bilalkhokhar/Desktop/asadrkhokar/data-science-portfolio'\n",
    "\n",
    "# Make sure folder exists\n",
    "os.makedirs(custom_path, exist_ok=True)\n",
    "\n",
    "# Change working directory\n",
    "os.chdir(custom_path)\n",
    "\n",
    "# Now run kaggle download command here\n",
    "!kaggle competitions download -c store-sales-time-series-forecasting\n",
    "\n",
    "# Unzip here as well\n",
    "!unzip -q store-sales-time-series-forecasting.zip -d store-sales-time-series-forecasting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data as pandas dataframes\n",
    "train_df = pd.read_csv('store-sales-time-series-forecasting/train.csv')\n",
    "stores_df = pd.read_csv('store-sales-time-series-forecasting/stores.csv')\n",
    "transactions_df = pd.read_csv('store-sales-time-series-forecasting/transactions.csv')\n",
    "oil_df = pd.read_csv('store-sales-time-series-forecasting/oil.csv')\n",
    "holidays_events_df = pd.read_csv('store-sales-time-series-forecasting/holidays_events.csv')\n",
    "test_df = pd.read_csv('store-sales-time-series-forecasting/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking counts, data types and statistics for each dataframe and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- train_df --------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000888 entries, 0 to 3000887\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   id           int64  \n",
      " 1   date         object \n",
      " 2   store_nbr    int64  \n",
      " 3   family       object \n",
      " 4   sales        float64\n",
      " 5   onpromotion  int64  \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 137.4+ MB\n",
      "                 id     store_nbr         sales   onpromotion\n",
      "count  3.000888e+06  3.000888e+06  3.000888e+06  3.000888e+06\n",
      "mean   1.500444e+06  2.750000e+01  3.577757e+02  2.602770e+00\n",
      "std    8.662819e+05  1.558579e+01  1.101998e+03  1.221888e+01\n",
      "min    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00\n",
      "25%    7.502218e+05  1.400000e+01  0.000000e+00  0.000000e+00\n",
      "50%    1.500444e+06  2.750000e+01  1.100000e+01  0.000000e+00\n",
      "75%    2.250665e+06  4.100000e+01  1.958473e+02  0.000000e+00\n",
      "max    3.000887e+06  5.400000e+01  1.247170e+05  7.410000e+02\n",
      "\n",
      "-------------------- test_df --------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28512 entries, 0 to 28511\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           28512 non-null  int64 \n",
      " 1   date         28512 non-null  object\n",
      " 2   store_nbr    28512 non-null  int64 \n",
      " 3   family       28512 non-null  object\n",
      " 4   onpromotion  28512 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "                 id     store_nbr   onpromotion\n",
      "count  2.851200e+04  28512.000000  28512.000000\n",
      "mean   3.015144e+06     27.500000      6.965383\n",
      "std    8.230850e+03     15.586057     20.683952\n",
      "min    3.000888e+06      1.000000      0.000000\n",
      "25%    3.008016e+06     14.000000      0.000000\n",
      "50%    3.015144e+06     27.500000      0.000000\n",
      "75%    3.022271e+06     41.000000      6.000000\n",
      "max    3.029399e+06     54.000000    646.000000\n",
      "\n",
      "-------------------- stores_df --------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   store_nbr  54 non-null     int64 \n",
      " 1   city       54 non-null     object\n",
      " 2   state      54 non-null     object\n",
      " 3   type       54 non-null     object\n",
      " 4   cluster    54 non-null     int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.2+ KB\n",
      "       store_nbr    cluster\n",
      "count  54.000000  54.000000\n",
      "mean   27.500000   8.481481\n",
      "std    15.732133   4.693395\n",
      "min     1.000000   1.000000\n",
      "25%    14.250000   4.000000\n",
      "50%    27.500000   8.500000\n",
      "75%    40.750000  13.000000\n",
      "max    54.000000  17.000000\n",
      "\n",
      "-------------------- transactions_df --------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83488 entries, 0 to 83487\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   date          83488 non-null  object\n",
      " 1   store_nbr     83488 non-null  int64 \n",
      " 2   transactions  83488 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.9+ MB\n",
      "          store_nbr  transactions\n",
      "count  83488.000000  83488.000000\n",
      "mean      26.939237   1694.602158\n",
      "std       15.608204    963.286644\n",
      "min        1.000000      5.000000\n",
      "25%       13.000000   1046.000000\n",
      "50%       27.000000   1393.000000\n",
      "75%       40.000000   2079.000000\n",
      "max       54.000000   8359.000000\n",
      "\n",
      "-------------------- oil_df --------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1218 entries, 0 to 1217\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        1218 non-null   object \n",
      " 1   dcoilwtico  1175 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 19.2+ KB\n",
      "        dcoilwtico\n",
      "count  1175.000000\n",
      "mean     67.714366\n",
      "std      25.630476\n",
      "min      26.190000\n",
      "25%      46.405000\n",
      "50%      53.190000\n",
      "75%      95.660000\n",
      "max     110.620000\n",
      "\n",
      "-------------------- holidays_events_df --------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 350 entries, 0 to 349\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         350 non-null    object\n",
      " 1   type         350 non-null    object\n",
      " 2   locale       350 non-null    object\n",
      " 3   locale_name  350 non-null    object\n",
      " 4   description  350 non-null    object\n",
      " 5   transferred  350 non-null    bool  \n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 14.1+ KB\n",
      "              date     type    locale locale_name description transferred\n",
      "count          350      350       350         350         350         350\n",
      "unique         312        6         3          24         103           2\n",
      "top     2014-06-25  Holiday  National     Ecuador    Carnaval       False\n",
      "freq             4      221       174         174          10         338\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_list = [train_df, test_df, stores_df, transactions_df, oil_df, holidays_events_df]\n",
    "df_names = ['train_df', 'test_df', 'stores_df', 'transactions_df', 'oil_df', 'holidays_events_df']\n",
    "\n",
    "for df, df_name in zip(df_list, df_names):\n",
    "    print(f\"\\n{'-'*20} {df_name} {'-'*20}\")\n",
    "    df.info()\n",
    "    print(df.describe()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Dataset              | Data cleaning needed?                                               |\n",
    "| -------------------- | ------------------------------------------------------------------- |\n",
    "| train\\_df            | Convert `date` to datetime                                          |\n",
    "| test\\_df            | Convert `date` to datetime                                          |\n",
    "| stores\\_df           | Check categorical consistency                                       |\n",
    "| transactions\\_df     | Convert `date` to datetime                                          |\n",
    "| oil\\_df              | Convert `date` to datetime; handle missing in `dcoilwtico`          |\n",
    "| holidays\\_events\\_df | Convert `date` to datetime; check duplicate dates (multiple events) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "transactions_df['date'] = pd.to_datetime(transactions_df['date'])\n",
    "oil_df['date'] = pd.to_datetime(oil_df['date'])\n",
    "holidays_events_df['date'] = pd.to_datetime(holidays_events_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date           0\n",
      "dcoilwtico    43\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(oil_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/w4wyl1x53ts_0w53vszs_s_c0000gn/T/ipykernel_65092/3331926355.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  oil_df['dcoilwtico'] = oil_df['dcoilwtico'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Forward fill missing oil prices (commonly used in time series when price data is missing)\n",
    "oil_df['dcoilwtico'] = oil_df['dcoilwtico'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/w4wyl1x53ts_0w53vszs_s_c0000gn/T/ipykernel_65092/2266859746.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  oil_df['dcoilwtico'] = oil_df['dcoilwtico'].fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# If first value(s) are still NaN after ffill, can backward fill\n",
    "oil_df['dcoilwtico'] = oil_df['dcoilwtico'].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df duplicated rows: 0\n",
      "test_df duplicated rows: 0\n",
      "transactions_df duplicated rows: 0\n",
      "oil_df duplicated rows: 0\n",
      "holidays_events_df duplicated rows: 0\n",
      "stores_df duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check duplicated rows\n",
    "print(\"train_df duplicated rows:\", train_df.duplicated().sum())\n",
    "print(\"test_df duplicated rows:\", test_df.duplicated().sum())\n",
    "print(\"transactions_df duplicated rows:\", transactions_df.duplicated().sum())\n",
    "print(\"oil_df duplicated rows:\", oil_df.duplicated().sum())\n",
    "print(\"holidays_events_df duplicated rows:\", holidays_events_df.duplicated().sum())\n",
    "print(\"stores_df duplicated rows:\", stores_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stores_df city: ['Quito' 'Santo Domingo' 'Cayambe' 'Latacunga' 'Riobamba' 'Ibarra'\n",
      " 'Guaranda' 'Puyo' 'Ambato' 'Guayaquil' 'Salinas' 'Daule' 'Babahoyo'\n",
      " 'Quevedo' 'Playas' 'Libertad' 'Cuenca' 'Loja' 'Machala' 'Esmeraldas'\n",
      " 'Manta' 'El Carmen']\n",
      "stores_df state: ['Pichincha' 'Santo Domingo de los Tsachilas' 'Cotopaxi' 'Chimborazo'\n",
      " 'Imbabura' 'Bolivar' 'Pastaza' 'Tungurahua' 'Guayas' 'Santa Elena'\n",
      " 'Los Rios' 'Azuay' 'Loja' 'El Oro' 'Esmeraldas' 'Manabi']\n",
      "stores_df type: ['D' 'B' 'C' 'E' 'A']\n",
      "holidays_events_df type: ['Holiday' 'Transfer' 'Additional' 'Bridge' 'Work Day' 'Event']\n",
      "holidays_events_df locale: ['Local' 'Regional' 'National']\n"
     ]
    }
   ],
   "source": [
    "# Unique values in categorical columns\n",
    "print(\"stores_df city:\", stores_df['city'].unique())\n",
    "print(\"stores_df state:\", stores_df['state'].unique())\n",
    "print(\"stores_df type:\", stores_df['type'].unique())\n",
    "print(\"holidays_events_df type:\", holidays_events_df['type'].unique())\n",
    "print(\"holidays_events_df locale:\", holidays_events_df['locale'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative sales count (train_df): 0\n"
     ]
    }
   ],
   "source": [
    "# Negative sales?\n",
    "print(\"Negative sales count (train_df):\", (train_df['sales'] < 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train_df to start modelling dataframe\n",
    "train_df = train_df.copy()\n",
    "\n",
    "# Merge holidays/events info on 'date'\n",
    "train_df = train_df.merge(\n",
    "    holidays_events_df[['date', 'type', 'locale', 'locale_name', 'description', 'transferred']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge oil prices on 'date'\n",
    "train_df = train_df.merge(\n",
    "    oil_df[['date', 'dcoilwtico']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge transactions per store and date\n",
    "train_df = train_df.merge(\n",
    "    transactions_df,\n",
    "    on=['date', 'store_nbr'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge store metadata on 'store_nbr'\n",
    "train_df = train_df.merge(\n",
    "    stores_df,\n",
    "    on='store_nbr',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/w4wyl1x53ts_0w53vszs_s_c0000gn/T/ipykernel_65092/250967953.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df['dcoilwtico'] = train_df['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# Fill missing transactions with 0\n",
    "train_df['transactions'] = train_df['transactions'].fillna(0)\n",
    "\n",
    "# Fill missing oil prices forward then backward\n",
    "train_df['dcoilwtico'] = train_df['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "id                    0\n",
      "date                  0\n",
      "store_nbr             0\n",
      "family                0\n",
      "sales                 0\n",
      "onpromotion           0\n",
      "type_x          2551824\n",
      "locale          2551824\n",
      "locale_name     2551824\n",
      "description     2551824\n",
      "transferred     2551824\n",
      "dcoilwtico            0\n",
      "transactions          0\n",
      "city                  0\n",
      "state                 0\n",
      "type_y                0\n",
      "cluster               0\n",
      "year                  0\n",
      "month                 0\n",
      "day                   0\n",
      "dayofweek             0\n",
      "weekofyear            0\n",
      "is_weekend            0\n",
      "is_holiday            0\n",
      "family_enc            0\n",
      "dtype: int64\n",
      "   id       date store_nbr      family  sales  onpromotion   type_x    locale  \\\n",
      "0   0 2013-01-01         1  AUTOMOTIVE    0.0            0  Holiday  National   \n",
      "1   1 2013-01-01         1   BABY CARE    0.0            0  Holiday  National   \n",
      "2   2 2013-01-01         1      BEAUTY    0.0            0  Holiday  National   \n",
      "3   3 2013-01-01         1   BEVERAGES    0.0            0  Holiday  National   \n",
      "4   4 2013-01-01         1       BOOKS    0.0            0  Holiday  National   \n",
      "\n",
      "  locale_name         description  ... type_y  cluster  year month day  \\\n",
      "0     Ecuador  Primer dia del ano  ...      D       13  2013     1   1   \n",
      "1     Ecuador  Primer dia del ano  ...      D       13  2013     1   1   \n",
      "2     Ecuador  Primer dia del ano  ...      D       13  2013     1   1   \n",
      "3     Ecuador  Primer dia del ano  ...      D       13  2013     1   1   \n",
      "4     Ecuador  Primer dia del ano  ...      D       13  2013     1   1   \n",
      "\n",
      "  dayofweek  weekofyear  is_weekend  is_holiday  family_enc  \n",
      "0         1           1           0           1           0  \n",
      "1         1           1           0           1           1  \n",
      "2         1           1           0           1           2  \n",
      "3         1           1           0           1           3  \n",
      "4         1           1           0           1           4  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical columns from holidays/events and stores to category dtype\n",
    "categorical_cols = ['type', 'locale', 'locale_name', 'description', 'store_nbr', 'city', 'state', 'type_y'] \n",
    "for col in categorical_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "\n",
    "# Extract datetime features from 'date'\n",
    "train_df['year'] = train_df['date'].dt.year\n",
    "train_df['month'] = train_df['date'].dt.month\n",
    "train_df['day'] = train_df['date'].dt.day\n",
    "train_df['dayofweek'] = train_df['date'].dt.dayofweek\n",
    "train_df['weekofyear'] = train_df['date'].dt.isocalendar().week.astype(int)\n",
    "train_df['is_weekend'] = train_df['dayofweek'].isin([5,6]).astype(int)\n",
    "\n",
    "# Create is_holiday flag from holidays_events_df\n",
    "holiday_dates = holidays_events_df['date'].unique()\n",
    "train_df['is_holiday'] = train_df['date'].isin(holiday_dates).astype(int)\n",
    "\n",
    "# Label encode 'family' (main product category) \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_family = LabelEncoder()\n",
    "train_df['family_enc'] = le_family.fit_transform(train_df['family'])\n",
    "\n",
    "# Final check of missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Display the head of final modelling dataframe\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/w4wyl1x53ts_0w53vszs_s_c0000gn/T/ipykernel_65092/4008647085.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(train_df[col]):\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values in categorical columns (fill with 'Unknown')\n",
    "cat_cols = ['type', 'locale', 'locale_name', 'description', 'city', 'state', 'type_y']\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in train_df.columns:\n",
    "        if pd.api.types.is_categorical_dtype(train_df[col]):\n",
    "            # Add 'Unknown' to categories before filling\n",
    "            train_df[col] = train_df[col].cat.add_categories('Unknown')\n",
    "        train_df[col] = train_df[col].fillna('Unknown')\n",
    "\n",
    "# Create lag and rolling features for sales per 'id'\n",
    "train_df = train_df.sort_values(['id', 'date'])\n",
    "train_df['sales_lag_7'] = train_df.groupby('id')['sales'].shift(7)\n",
    "train_df['sales_roll_mean_7'] = train_df.groupby('id')['sales'].transform(lambda x: x.shift(1).rolling(window=7).mean())\n",
    "\n",
    "# Fill lag/rolling NaNs with 0 or some other strategy\n",
    "train_df['sales_lag_7'] = train_df['sales_lag_7'].fillna(0)\n",
    "train_df['sales_roll_mean_7'] = train_df['sales_roll_mean_7'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating modelling test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/w4wyl1x53ts_0w53vszs_s_c0000gn/T/ipykernel_65092/571963564.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_df['dcoilwtico'] = test_df['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/tt/w4wyl1x53ts_0w53vszs_s_c0000gn/T/ipykernel_65092/571963564.py:28: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test_df[col]):\n"
     ]
    }
   ],
   "source": [
    "# Merge supplementary data same as train\n",
    "test_df = test_df.merge(\n",
    "    holidays_events_df[['date', 'type', 'locale', 'locale_name', 'description', 'transferred']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "test_df = test_df.merge(\n",
    "    oil_df[['date', 'dcoilwtico']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "test_df = test_df.merge(\n",
    "    transactions_df,\n",
    "    on=['date', 'store_nbr'],\n",
    "    how='left'\n",
    ")\n",
    "test_df = test_df.merge(\n",
    "    stores_df,\n",
    "    on='store_nbr',\n",
    "    how='left'\n",
    ")\n",
    "test_df['transactions'] = test_df['transactions'].fillna(0)\n",
    "test_df['dcoilwtico'] = test_df['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Categorical columns: fillna and convert to category\n",
    "for col in cat_cols:\n",
    "    if col in test_df.columns:\n",
    "        if pd.api.types.is_categorical_dtype(test_df[col]):\n",
    "            test_df[col] = test_df[col].cat.add_categories('Unknown')\n",
    "        test_df[col] = test_df[col].fillna('Unknown')\n",
    "\n",
    "# Encode 'family' using trained encoder\n",
    "test_df['family_enc'] = le_family.transform(test_df['family'])\n",
    "\n",
    "# Extract date features\n",
    "test_df['year'] = test_df['date'].dt.year\n",
    "test_df['month'] = test_df['date'].dt.month\n",
    "test_df['day'] = test_df['date'].dt.day\n",
    "test_df['dayofweek'] = test_df['date'].dt.dayofweek\n",
    "test_df['weekofyear'] = test_df['date'].dt.isocalendar().week.astype(int)\n",
    "test_df['is_weekend'] = test_df['dayofweek'].isin([5,6]).astype(int)\n",
    "test_df['is_holiday'] = test_df['date'].isin(holiday_dates).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full modularised and reproducible pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/w4wyl1x53ts_0w53vszs_s_c0000gn/T/ipykernel_65092/3110786703.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  oil_df['dcoilwtico'] = oil_df['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/tt/w4wyl1x53ts_0w53vszs_s_c0000gn/T/ipykernel_65092/3110786703.py:99: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df['dcoilwtico'] = train_df['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/tt/w4wyl1x53ts_0w53vszs_s_c0000gn/T/ipykernel_65092/3110786703.py:131: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_df['dcoilwtico'] = test_df['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed train sample:\n",
      "   id       date store_nbr      family  sales  onpromotion holiday_type  \\\n",
      "0   0 2013-01-01         1  AUTOMOTIVE    0.0            0      Holiday   \n",
      "1   1 2013-01-01         1   BABY CARE    0.0            0      Holiday   \n",
      "2   2 2013-01-01         1      BEAUTY    0.0            0      Holiday   \n",
      "3   3 2013-01-01         1   BEVERAGES    0.0            0      Holiday   \n",
      "4   4 2013-01-01         1       BOOKS    0.0            0      Holiday   \n",
      "\n",
      "     locale locale_name         description  ...  year  month  day dayofweek  \\\n",
      "0  National     Ecuador  Primer dia del ano  ...  2013      1    1         1   \n",
      "1  National     Ecuador  Primer dia del ano  ...  2013      1    1         1   \n",
      "2  National     Ecuador  Primer dia del ano  ...  2013      1    1         1   \n",
      "3  National     Ecuador  Primer dia del ano  ...  2013      1    1         1   \n",
      "4  National     Ecuador  Primer dia del ano  ...  2013      1    1         1   \n",
      "\n",
      "  weekofyear is_weekend  is_holiday  family_enc  sales_lag_7  \\\n",
      "0          1          0           1           0          0.0   \n",
      "1          1          0           1           1          0.0   \n",
      "2          1          0           1           2          0.0   \n",
      "3          1          0           1           3          0.0   \n",
      "4          1          0           1           4          0.0   \n",
      "\n",
      "   sales_roll_mean_7  \n",
      "0                0.0  \n",
      "1                0.0  \n",
      "2                0.0  \n",
      "3                0.0  \n",
      "4                0.0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "Processed test sample:\n",
      "        id       date store_nbr      family  onpromotion holiday_type  \\\n",
      "0  3000888 2017-08-16         1  AUTOMOTIVE            0      Unknown   \n",
      "1  3000889 2017-08-16         1   BABY CARE            0      Unknown   \n",
      "2  3000890 2017-08-16         1      BEAUTY            2      Unknown   \n",
      "3  3000891 2017-08-16         1   BEVERAGES           20      Unknown   \n",
      "4  3000892 2017-08-16         1       BOOKS            0      Unknown   \n",
      "\n",
      "    locale locale_name description transferred  ...  store_type  cluster  \\\n",
      "0  Unknown     Unknown     Unknown         NaN  ...           D       13   \n",
      "1  Unknown     Unknown     Unknown         NaN  ...           D       13   \n",
      "2  Unknown     Unknown     Unknown         NaN  ...           D       13   \n",
      "3  Unknown     Unknown     Unknown         NaN  ...           D       13   \n",
      "4  Unknown     Unknown     Unknown         NaN  ...           D       13   \n",
      "\n",
      "   year month day  dayofweek  weekofyear  is_weekend  is_holiday  family_enc  \n",
      "0  2017     8  16          2          33           0           0           0  \n",
      "1  2017     8  16          2          33           0           0           1  \n",
      "2  2017     8  16          2          33           0           0           2  \n",
      "3  2017     8  16          2          33           0           0           3  \n",
      "4  2017     8  16          2          33           0           0           4  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Missing values in train_df after preprocessing:\n",
      "id                         0\n",
      "date                       0\n",
      "store_nbr                  0\n",
      "family                     0\n",
      "sales                      0\n",
      "onpromotion                0\n",
      "holiday_type               0\n",
      "locale                     0\n",
      "locale_name                0\n",
      "description                0\n",
      "transferred          2551824\n",
      "dcoilwtico                 0\n",
      "transactions               0\n",
      "city                       0\n",
      "state                      0\n",
      "store_type                 0\n",
      "cluster                    0\n",
      "year                       0\n",
      "month                      0\n",
      "day                        0\n",
      "dayofweek                  0\n",
      "weekofyear                 0\n",
      "is_weekend                 0\n",
      "is_holiday                 0\n",
      "family_enc                 0\n",
      "sales_lag_7                0\n",
      "sales_roll_mean_7          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def load_data(base_path='store-sales-time-series-forecasting'):\n",
    "    \"\"\"Load all datasets.\"\"\"\n",
    "    train_df = pd.read_csv(f'{base_path}/train.csv')\n",
    "    test_df = pd.read_csv(f'{base_path}/test.csv')\n",
    "    stores_df = pd.read_csv(f'{base_path}/stores.csv')\n",
    "    transactions_df = pd.read_csv(f'{base_path}/transactions.csv')\n",
    "    oil_df = pd.read_csv(f'{base_path}/oil.csv')\n",
    "    holidays_events_df = pd.read_csv(f'{base_path}/holidays_events.csv')\n",
    "    return train_df, test_df, stores_df, transactions_df, oil_df, holidays_events_df\n",
    "\n",
    "def preprocess_dates(*dfs):\n",
    "    \"\"\"Convert date columns to datetime.\"\"\"\n",
    "    for df in dfs:\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "def fill_oil_prices(oil_df):\n",
    "    \"\"\"Fill missing oil prices forward then backward.\"\"\"\n",
    "    oil_df['dcoilwtico'] = oil_df['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n",
    "    return oil_df\n",
    "\n",
    "def fill_missing_and_convert_cats(df, cat_cols):\n",
    "    \"\"\"Fill NA with 'Unknown' before converting to categorical dtype.\"\"\"\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "def extract_date_features(df):\n",
    "    \"\"\"Extract common datetime features.\"\"\"\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['weekofyear'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    df['is_weekend'] = df['dayofweek'].isin([5,6]).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_holiday_flag(df, holidays_events_df):\n",
    "    \"\"\"Add is_holiday flag based on holidays_events_df.\"\"\"\n",
    "    holiday_dates = holidays_events_df['date'].unique()\n",
    "    df['is_holiday'] = df['date'].isin(holiday_dates).astype(int)\n",
    "    return df\n",
    "\n",
    "def merge_external_data(df, holidays_events_df, oil_df, transactions_df, stores_df):\n",
    "    \"\"\"Merge all external data on date/store keys and rename columns for clarity.\"\"\"\n",
    "    \n",
    "    # Rename 'type' in stores_df to 'store_type'\n",
    "    stores_df = stores_df.rename(columns={'type': 'store_type'})\n",
    "    \n",
    "    # Rename 'type' in holidays_events_df to 'holiday_type' before merging\n",
    "    holidays_events_df = holidays_events_df.rename(columns={'type': 'holiday_type'})\n",
    "    \n",
    "    df = df.merge(\n",
    "        holidays_events_df[['date', 'holiday_type', 'locale', 'locale_name', 'description', 'transferred']],\n",
    "        on='date', how='left'\n",
    "    )\n",
    "    df = df.merge(\n",
    "        oil_df[['date', 'dcoilwtico']],\n",
    "        on='date', how='left'\n",
    "    )\n",
    "    df = df.merge(\n",
    "        transactions_df,\n",
    "        on=['date', 'store_nbr'], how='left'\n",
    "    )\n",
    "    df = df.merge(\n",
    "        stores_df,\n",
    "        on='store_nbr', how='left'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def fill_missing_and_convert_cats(df, cat_cols):\n",
    "    \"\"\"Fill NA with 'Unknown' before converting to categorical dtype.\"\"\"\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "def preprocess_train(train_df, holidays_events_df, oil_df, transactions_df, stores_df, seed=42):\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Merge external info with renamed columns\n",
    "    train_df = merge_external_data(train_df, holidays_events_df, oil_df, transactions_df, stores_df)\n",
    "    \n",
    "    # Fill missing values before category conversion\n",
    "    train_df['transactions'] = train_df['transactions'].fillna(0)\n",
    "    train_df['dcoilwtico'] = train_df['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    cat_cols = ['holiday_type', 'locale', 'locale_name', 'description', 'city', 'state', 'store_type', 'store_nbr']\n",
    "    train_df = fill_missing_and_convert_cats(train_df, cat_cols)\n",
    "    \n",
    "    # Date features & holiday flag\n",
    "    train_df = extract_date_features(train_df)\n",
    "    train_df = add_holiday_flag(train_df, holidays_events_df)\n",
    "    \n",
    "    # Label encode 'family'\n",
    "    le_family = LabelEncoder()\n",
    "    train_df['family_enc'] = le_family.fit_transform(train_df['family'])\n",
    "    \n",
    "    # Sort for lag features\n",
    "    train_df = train_df.sort_values(['id', 'date'])\n",
    "    train_df['sales_lag_7'] = train_df.groupby('id')['sales'].shift(7)\n",
    "    train_df['sales_roll_mean_7'] = train_df.groupby('id')['sales'].transform(lambda x: x.shift(1).rolling(window=7).mean())\n",
    "    \n",
    "    # Fill lag/rolling NaNs\n",
    "    train_df['sales_lag_7'] = train_df['sales_lag_7'].fillna(0)\n",
    "    train_df['sales_roll_mean_7'] = train_df['sales_roll_mean_7'].fillna(0)\n",
    "    \n",
    "    return train_df, le_family\n",
    "\n",
    "def preprocess_test(test_df, holidays_events_df, oil_df, transactions_df, stores_df, le_family, seed=42):\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Merge external info with renamed columns\n",
    "    test_df = merge_external_data(test_df, holidays_events_df, oil_df, transactions_df, stores_df)\n",
    "    \n",
    "    # Fill missing values before category conversion\n",
    "    test_df['transactions'] = test_df['transactions'].fillna(0)\n",
    "    test_df['dcoilwtico'] = test_df['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    cat_cols = ['holiday_type', 'locale', 'locale_name', 'description', 'city', 'state', 'store_type', 'store_nbr']\n",
    "    test_df = fill_missing_and_convert_cats(test_df, cat_cols)\n",
    "    \n",
    "    # Date features & holiday flag\n",
    "    test_df = extract_date_features(test_df)\n",
    "    test_df = add_holiday_flag(test_df, holidays_events_df)\n",
    "    \n",
    "    # Label encode 'family' using existing encoder\n",
    "    test_df['family_enc'] = le_family.transform(test_df['family'])\n",
    "    \n",
    "    # No lag features for test (no sales column)\n",
    "    return test_df\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    train_df, test_df, stores_df, transactions_df, oil_df, holidays_events_df = load_data()\n",
    "    \n",
    "    # Convert dates\n",
    "    preprocess_dates(train_df, test_df, transactions_df, oil_df, holidays_events_df)\n",
    "    \n",
    "    # Fill oil prices missing values\n",
    "    oil_df = fill_oil_prices(oil_df)\n",
    "    \n",
    "    # Preprocess train and test\n",
    "    train_df_processed, le_family = preprocess_train(train_df, holidays_events_df, oil_df, transactions_df, stores_df)\n",
    "    test_df_processed = preprocess_test(test_df, holidays_events_df, oil_df, transactions_df, stores_df, le_family)\n",
    "    \n",
    "    print(\"\\nProcessed train sample:\")\n",
    "    print(train_df_processed.head())\n",
    "    \n",
    "    print(\"\\nProcessed test sample:\")\n",
    "    print(test_df_processed.head())\n",
    "    \n",
    "    # Check missing values in train\n",
    "    print(\"\\nMissing values in train_df after preprocessing:\")\n",
    "    print(train_df_processed.isnull().sum())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
